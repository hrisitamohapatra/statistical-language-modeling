{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaWw6SwXM-tM",
        "outputId": "f37e9508-7906-4b57-c634-8dc436e80499"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading: Pride and Prejudice\n",
            "Loading: Little Women\n",
            "Loading: Alice in Wonderland\n",
            "Loading: Sherlock Holmes\n",
            "\n",
            "Corpus Statistics:\n",
            "Total tokens: 459274\n",
            "Vocabulary size: 16449\n",
            "Unique bigrams: 169160\n",
            "Unique trigrams: 359239\n",
            "\n",
            "--- NEXT WORD PREDICTION ---\n",
            "Enter one or two words (e.g., 'to be') or type 'exit' to quit.\n",
            "\n",
            "Input: to be\n",
            "Trigram Predictions: ['a', 'the', 'sure', 'in', 'so'] \n",
            "\n",
            "Input: what\n",
            "Bigram Predictions: ['i', 'is', 'she', 'a', 'you'] \n",
            "\n",
            "Input: you are\n",
            "Trigram Predictions: ['not', 'a', 'very', 'the', 'too'] \n",
            "\n",
            "Input: clear\n",
            "Bigram Predictions: ['to', 'that', 'up', 'the', 'enough'] \n",
            "\n",
            "Input: exit\n",
            "Exiting prediction.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "# STEP 1: CORPUS CREATION\n",
        "\n",
        "BOOK_URLS = {\n",
        "    \"Pride and Prejudice\": \"https://www.gutenberg.org/files/1342/1342-0.txt\",\n",
        "    \"Little Women\": \"https://www.gutenberg.org/files/514/514-0.txt\",\n",
        "    \"Alice in Wonderland\": \"https://www.gutenberg.org/files/11/11-0.txt\",\n",
        "    \"Sherlock Holmes\": \"https://www.gutenberg.org/files/1661/1661-0.txt\"\n",
        "}\n",
        "\n",
        "def load_corpus(urls):\n",
        "    text = \"\"\n",
        "    for title, url in urls.items():\n",
        "        print(f\"Loading: {title}\")\n",
        "        text += requests.get(url).text + \"\\n\"\n",
        "    return text\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text.split()\n",
        "\n",
        "raw_text = load_corpus(BOOK_URLS)\n",
        "tokens = preprocess(raw_text)\n",
        "\n",
        "print(\"\\nCorpus Statistics:\")\n",
        "print(\"Total tokens:\", len(tokens))\n",
        "\n",
        "# STEP 2: N-GRAM CONSTRUCTION\n",
        "\n",
        "unigrams = Counter(tokens)\n",
        "bigrams = Counter(zip(tokens[:-1], tokens[1:]))\n",
        "trigrams = Counter(zip(tokens[:-2], tokens[1:-1], tokens[2:]))\n",
        "\n",
        "V = len(unigrams)\n",
        "\n",
        "print(\"Vocabulary size:\", V)\n",
        "print(\"Unique bigrams:\", len(bigrams))\n",
        "print(\"Unique trigrams:\", len(trigrams))\n",
        "\n",
        "# STEP 3: PROBABILITY FUNCTIONS (ADD-1 SMOOTHING)\n",
        "\n",
        "def bigram_probability(w1, w2):\n",
        "    return (bigrams[(w1, w2)] + 1) / (unigrams[w1] + V)\n",
        "\n",
        "def trigram_probability(w1, w2, w3):\n",
        "    return (trigrams[(w1, w2, w3)] + 1) / (bigrams[(w1, w2)] + V)\n",
        "\n",
        "# STEP 4: NEXT WORD PREDICTION\n",
        "\n",
        "def predict_next_bigram(word, top_k=5):\n",
        "    candidates = {}\n",
        "    for (w1, w2), _ in bigrams.items():\n",
        "        if w1 == word:\n",
        "            candidates[w2] = bigram_probability(w1, w2)\n",
        "\n",
        "    return sorted(candidates, key=candidates.get, reverse=True)[:top_k]\n",
        "\n",
        "def predict_next_trigram(w1, w2, top_k=5):\n",
        "    candidates = {}\n",
        "    context_count = bigrams[(w1, w2)]\n",
        "\n",
        "    if context_count == 0:\n",
        "        # Backoff to bigram model\n",
        "        return predict_next_bigram(w2, top_k)\n",
        "\n",
        "    for word in unigrams:\n",
        "        candidates[word] = trigram_probability(w1, w2, word)\n",
        "\n",
        "    return sorted(candidates, key=candidates.get, reverse=True)[:top_k]\n",
        "\n",
        "# STEP 5: INTERACTIVE USER PROMPT\n",
        "\n",
        "def interactive_prediction():\n",
        "    print(\"\\n--- NEXT WORD PREDICTION ---\")\n",
        "    print(\"Enter one or two words (e.g., 'to be') or type 'exit' to quit.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"Input: \").lower().strip()\n",
        "        if user_input == \"exit\":\n",
        "            print(\"Exiting prediction.\")\n",
        "            break\n",
        "\n",
        "        words = user_input.split()\n",
        "\n",
        "        if len(words) == 1:\n",
        "            word = words[0]\n",
        "            if word not in unigrams:\n",
        "                print(\"Word not found in vocabulary.\\n\")\n",
        "                continue\n",
        "            predictions = predict_next_bigram(word)\n",
        "            print(\"Bigram Predictions:\", predictions, \"\\n\")\n",
        "\n",
        "        elif len(words) == 2:\n",
        "            w1, w2 = words\n",
        "            predictions = predict_next_trigram(w1, w2)\n",
        "            print(\"Trigram Predictions:\", predictions, \"\\n\")\n",
        "\n",
        "        else:\n",
        "            print(\"Please enter only one or two words.\\n\")\n",
        "\n",
        "interactive_prediction()\n"
      ]
    }
  ]
}